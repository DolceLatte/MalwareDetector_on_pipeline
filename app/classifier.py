import torch
import pefile
import pandas as pd
import re
import math
import numpy as np
import torch.nn as nn
import torch.nn.functional as F

use_cuda = torch.cuda.is_available()

MaxChunkLen = 3600

sections_map = {'.header': 1, '.text': 2, '.data': 3, '.idata': 4, '.edata': 5, '.pdata': 6,
                '.rsrc': 7, '.reloc': 8, '.rdata': 9, '.sdata': 10, '.xdata': 11,
                '.tls': 12, 'Shared':13,'INIT':14,'PAGE':15,'Undefined': 16}

def splitPEfile(line, label):
    start = 0
    fileChunklen = 4096
    list = []

    while True:
        list.append(line[start:fileChunklen])
        if len(line) <= 4096:
            break
        if len(line[fileChunklen:]) <= 4096:
            list.append(line[fileChunklen:])
            break
        else:
            start = fileChunklen
            fileChunklen += 4096

    encoding = np.eye(16)[label - 1]
    result = []
    for l in list:
        row = np.concatenate(([H(l)], encoding), axis=0)
        result.append(row)
    return result


def H(data):
    if not data:
        return 0
    entropy = 0
    for x in range(256):
        p_x = float(data.count(x)) / len(data)
        if p_x > 0:
            result = - p_x * math.log(p_x, 2)
            entropy += result
    return entropy

def returnEntropy(path):
        f = open(path, 'rb')
        pe = pefile.PE(path)
        full_file_data = f.read()
        feature = []

        if len(pe.sections) == 0:
            return False

        point = pe.sections[0].PointerToRawData

        list = splitPEfile(full_file_data[:point], 1)
        feature.append(list)

        for section in pe.sections:
            try:
                sname = re.sub('\x00', '', section.Name.decode())
                if sname not in sections_map.keys():
                    label = 16
                else:
                    label = sections_map[sname]

                list = splitPEfile(section.get_data(), label)
                feature.append(list)

            except:
                label = 16
                list = splitPEfile(section.get_data(), label)
                feature.append(list)
                continue

        answer = []
        for fea in feature:
            answer += fea

        df = pd.DataFrame(answer)

        data_with_padding = np.zeros((1,MaxChunkLen,17))
        data_non_pad = df.values

        if len(data_non_pad) < MaxChunkLen:
            tp = MaxChunkLen - len(data_non_pad)
            padArray = np.zeros((tp, 17))
            data_non_pad = np.vstack((data_non_pad, padArray))
        else:
            data_non_pad = data_non_pad[:MaxChunkLen]
        data_with_padding[0] = data_non_pad

        return data_with_padding

class CNNClassifier_custom(nn.Module):
    def __init__(self):
        # 항상 torch.nn.Module을 상속받고 시작
        super(CNNClassifier_custom, self).__init__()
        conv1 = nn.Conv1d(17, 50, 3)
        # activation ReLU
        pool1 = nn.MaxPool1d(2)
        conv2 = nn.Conv1d(50, 70, 3)
        # activation ReLU
        pool2 = nn.MaxPool1d(2)
        conv3 = nn.Conv1d(70, 70, 3)
        # activation ReLU
        pool3 = nn.MaxPool1d(2)
        ReLU = nn.ReLU()
        self.conv_module = nn.Sequential(
            conv1,
            nn.BatchNorm1d(50, affine=True),
            nn.ReLU(),
            pool1,
            conv2,
            nn.BatchNorm1d(70, affine=True),
            nn.ReLU(),
            pool2,
            conv3,
            nn.BatchNorm1d(70, affine=True),
            nn.ReLU(),
            pool3,
        )

        fc1 = nn.Linear(31360, 1000)
        fc2 = nn.Linear(1000, 300)
        fc3 = nn.Linear(300, 9)
        fc4 = nn.Linear(9, 2)

        self.fc_module = nn.Sequential(
            fc1,
            nn.BatchNorm1d(1000),
            nn.ReLU(),
            fc2,
            nn.BatchNorm1d(300),
            nn.ReLU(),
            fc3,
            nn.BatchNorm1d(9),
            nn.ReLU(),
            fc4
        )

        # gpu로 할당
        if use_cuda:
            self.conv_module = self.conv_module.cuda()
            self.fc_module = self.fc_module.cuda()

    def forward(self, x):
        out = self.conv_module(x)
        # make linear
        dim = 1
        for d in out.size()[1:]:
            dim = dim * d
        out = out.view(-1, dim)
        out = self.fc_module(out)
        return F.softmax(out, dim=1)

class Classifier(object):
    def __init__(self,param):
        self.model = CNNClassifier_custom()
        self.model.load_state_dict(param)
        self.model.eval()

    def predict(self, path):
        val_x = returnEntropy(path)
        val_x = torch.tensor(val_x, dtype=torch.float32)
        if use_cuda:
            val_x = val_x.cuda()
        val_x = val_x.transpose(1, 2)
        val_output = self.model(val_x)
        val = val_output.detach().cpu()
        probability = val.clone().numpy().tolist()[0]
        model_label = val.argmax(dim=1).numpy().tolist()
        index = model_label[0]

        return index, probability