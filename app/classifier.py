import torch
import pefile
import pandas as pd
import re
import math
import numpy as np

use_cuda = torch.cuda.is_available()

MaxChunkLen = 3600

sections_map = {'.header': 1, '.text': 2, '.data': 3, '.idata': 4, '.edata': 5, '.pdata': 6,
                '.rsrc': 7, '.reloc': 8, '.rdata': 9, '.sdata': 10, '.xdata': 11,
                '.tls': 12, 'Shared':13,'INIT':14,'PAGE':15,'Undefined': 16}

def splitPEfile(line, label):
    start = 0
    fileChunklen = 4096
    list = []

    while True:
        list.append(line[start:fileChunklen])
        if len(line) <= 4096:
            break
        if len(line[fileChunklen:]) <= 4096:
            list.append(line[fileChunklen:])
            break
        else:
            start = fileChunklen
            fileChunklen += 4096

    encoding = np.eye(16)[label - 1]
    result = []
    for l in list:
        row = np.concatenate(([H(l)], encoding), axis=0)
        result.append(row)
    return result


def H(data):
    if not data:
        return 0
    entropy = 0
    for x in range(256):
        p_x = float(data.count(x)) / len(data)
        if p_x > 0:
            result = - p_x * math.log(p_x, 2)
            entropy += result
    return entropy

def returnEntropy(path):
        f = open(path, 'rb')
        pe = pefile.PE(path)
        full_file_data = f.read()
        feature = []

        if len(pe.sections) == 0:
            return False

        point = pe.sections[0].PointerToRawData

        list = splitPEfile(full_file_data[:point], 1)
        feature.append(list)

        for section in pe.sections:
            try:
                sname = re.sub('\x00', '', section.Name.decode())
                if sname not in sections_map.keys():
                    label = 16
                else:
                    label = sections_map[sname]

                list = splitPEfile(section.get_data(), label)
                feature.append(list)

            except:
                label = 16
                list = splitPEfile(section.get_data(), label)
                feature.append(list)
                continue

        answer = []
        for fea in feature:
            answer += fea

        df = pd.DataFrame(answer)

        data_with_padding = np.zeros((1,MaxChunkLen,17))
        data_non_pad = df.values

        if len(data_non_pad) < MaxChunkLen:
            tp = MaxChunkLen - len(data_non_pad)
            padArray = np.zeros((tp, 17))
            data_non_pad = np.vstack((data_non_pad, padArray))
        else:
            data_non_pad = data_non_pad[:MaxChunkLen]
        data_with_padding[0] = data_non_pad

        return data_with_padding

class Classifier():
    def __init__(self,param):
        self.model = param
        self.model.eval()

    def predict(self, path):
        val_x = returnEntropy(path)
        val_x = torch.tensor(val_x, dtype=torch.float32)
        if use_cuda:
            val_x = val_x.cuda()
        val_x = val_x.transpose(1, 2)
        val_output = self.model(val_x)
        val = val_output.detach().cpu()
        probability = val.clone().numpy().tolist()[0]
        model_label = val.argmax(dim=1).numpy().tolist()
        index = model_label[0]

        return index, probability